{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2de61a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45e3e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7a981f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have real-time data access to provide the latest news on Amazon stock or any other financial information. For the most current updates on Amazon's stock, I recommend checking financial news websites, stock market apps, or financial news channels. You can also look at Amazon's stock performance on platforms like Yahoo Finance, Google Finance, or Bloomberg.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 14, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cwb0mcHL4iMMeqLGIH1mZWQzfTcdb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019ba9dc-0a28-7651-82b1-462a824fbef7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 68, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is latest news on Amazon Stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9224194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "system_instructions='You are an expert of sarcasm and provide responses accordingly.'\n",
    "user_query=\"What is latest news on Amazon Stock\"\n",
    "def call_llm(system_instructions, user_query):\n",
    "    response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=system_instructions,\n",
    "    input=user_query\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebf71d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions='You are an expert of sercasm and provide responses accordingly.'\n",
    "response=call_llm(system_instructions, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a6b53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I'm sure Amazon's stock has either skyrocketed to the moon or plummeted into the abyss—because, you know, that's the only two options with stocks these days! Just Google \"Amazon stock news,\" and you’ll find all the drama you need. Spoiler alert: Someone probably got rich or lost a fortune!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533844d7",
   "metadata": {},
   "source": [
    "# Define the system prompt\n",
    "# This prompt is used to guide the model's behavior.\n",
    "# It tells the model that it is a tool-using assistant and that it must respond with ONLY valid JSON (no markdown, no explanation).\n",
    "# It also defines the schema for the tool call JSON that the model will output.\n",
    "\n",
    "# here we are saying to follow strcit json and providing format of json that model will output\n",
    "# and we are also providing available tools and their signatures\n",
    "# which will help model to create argument properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44ce990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions=f\"\"\"\"\n",
    "You are tool-using assistant. \n",
    "You must response ONLY in JSON format as described below (no Markdowns, no explainations) if tool is being used.\n",
    "\n",
    "schema:\n",
    "- If you want to call a tool, respond with arguments as dictionary) :\n",
    "{{\"tool\":\"<tool_name>\",\"args\":{...}}}\n",
    "- set final=none only if tool is not needed.\n",
    "- If no tool is needed:\n",
    "  {{\"tool\":\"none\",\"final\":\"<your answer>\"}}\n",
    "\n",
    "\n",
    "Avaliable tools:\n",
    "1. Count_character(text: string, letter:string)->integer: Counts occurance of give character in the word. \n",
    "Example: Count_character(text:\"hello\",letter: \"l\") counts number of 'l'characters in a given text and \n",
    "will give answer as 2.)\n",
    "2. add_numbers (a: float, b:float)->float: Adds two numbers and returns the result. \n",
    "If more or less than 2 number are provided then do not use this tool.\n",
    "Example: add_numbers('a':2,'b':3) will return 5.\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77ee89",
   "metadata": {},
   "source": [
    "# Define the tool call schema\n",
    "# This schema defines the structure of the tool call JSON that the model will output.\n",
    "# It includes the tool name, its arguments, and a final answer if no tool is needed.\n",
    "# This is used to validate the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4568a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Literal, Optional\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "class ToolCall(BaseModel):\n",
    "    # Literal[...] is a specialized type hint used to restrict a variable to a specific set of exact values\n",
    "    tool: Literal[\"Count_character\", \"add_numbers\", \"none\"] \n",
    "    args: Dict[str, Any] = Field(default_factory=dict) # tool arguments dictionary\n",
    "    # Dict[str, Any] is a dictionary with string keys and any values\n",
    "    # Field(default_factory=dict) is a field that is a dictionary with string keys and any values\n",
    "    # default_factory=dict is a default factory that returns a dictionary with string keys and any values\n",
    "    # Optional[str] is an optional string   \n",
    "    final: Optional[str] = None  # final answer if no tool is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c8a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining Count_character tool\n",
    "def Count_character(text: str, letter: str) -> int:\n",
    "    return text.lower().count(letter.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f8f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define add_numbers tool\n",
    "def add_numbers(a: float, b: float) -> float:\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a2f7d",
   "metadata": {},
   "source": [
    "# Define the function to get the tool decision\n",
    "# This function takes a user message and returns a ToolCall object.\n",
    "# It uses the OpenAI client to call the model and get the response.\n",
    "# It then validates the response and returns a ToolCall object.\n",
    "# If the response is not valid JSON, it raises an error.\n",
    "\n",
    "# ToolCall.model_validate is going to validate the response returned by model\n",
    "# it is going to use ToolCall schema to validate the response which we defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2377dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_decision(user_query: str) -> ToolCall:\n",
    "    response_text=call_llm(system_instructions, user_query)\n",
    "    print(\"response_text:\", response_text)\n",
    "\n",
    "    try:\n",
    "        data=json.loads(response_text)\n",
    "        print(\"Json:\", data)\n",
    "        return ToolCall.model_validate(data)\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        raise RuntimeError(f\"Model did not return valid tool JSON.\\nRaw:\\n{response_text}\\n\\nError:\\n{e}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cd511080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_text: {\"tool\":\"Count_character\",\"args\":{\"text\":\"AI is my cup of tea!\",\"letter\":\"i\"}}\n",
      "Json: {'tool': 'Count_character', 'args': {'text': 'AI is my cup of tea!', 'letter': 'i'}}\n"
     ]
    }
   ],
   "source": [
    "call=get_tool_decision(\"How many letter i are there in 'AI is my cup of tea!'?\")\n",
    "call_json = call.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39e7a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS is a dict and it will give literal value as per the key passsed\n",
    "# and as model output is validated it must be having values like \"Count_character\", \"add_numbers\", \"none\"\n",
    "\n",
    "TOOLS = {\n",
    "    \"Count_character\": Count_character,\n",
    "    \"add_numbers\": add_numbers,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0875f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolCall(tool='Count_character', args={'text': 'AI is my cup of tea!', 'letter': 'i'}, final=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67da2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.Count_character(text: str, letter: str) -> int>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_to_be_used=TOOLS[call.tool]\n",
    "tool_to_be_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d77601e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'AI is my cup of tea!', 'letter': 'i'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking values of args\n",
    "call.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0af71189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call.args={'text': 'AI is my cup of tea!', 'letter': 'i'}\n",
    "#**call.args: This uses the double asterisk (dictionary unpacking) operator. \n",
    "# It takes the key-value pairs from the call.args dictionary and turns them into keyword arguments for the function\n",
    "# Is exactly the same as writing:result = Count_character(text='AI is my cup of tea!', letter='i')\n",
    "results=tool_to_be_used(**call.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aaff4b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93e66be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the result and which looks correct but model needs to take this result and provide answer in proper wording\n",
    "# so this result is actually context that are providing to use it for crafting answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026382a",
   "metadata": {},
   "source": [
    "This is the additional code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a1d80846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_answer(user_msg: str, call_json: str, tool_result: Any) -> str:\n",
    "    \"\"\"Ask the model to produce the final user-facing response using tool result.\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the tool result to answer.\"},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": call_json},\n",
    "            {\"role\": \"user\", \"content\": f\"Tool result: {tool_result}\\nNow answer clearly in 1-3 sentences.\"},\n",
    "        ],\n",
    "        temperature=0)\n",
    "    return resp.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c9fd8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"tool\":\"Count_character\",\"args\":{\"text\":\"AI is my cup of tea!\",\"letter\":\"i\"},\"final\":null}'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cd5161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_response:  There are 2 instances of the letter 'i' in the phrase \"AI is my cup of tea!\"\n"
     ]
    }
   ],
   "source": [
    "# calling the model again and providing following inputs\n",
    "# original question that was asked \n",
    "# output that model earlire provided\n",
    "# output of the tool calls \n",
    "\n",
    "model_response = get_final_answer(\"How many letter i are there in 'AI is my cup of tea!'?\", call_json, results)\n",
    "print(\"model_response: \", model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a2e56ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_text: {\"tool\":\"add_numbers\",\"args\":{\"a\":12.34,\"b\":45.12}}\n",
      "Json: {'tool': 'add_numbers', 'args': {'a': 12.34, 'b': 45.12}}\n",
      "model_response:  The sum of 12.34 and 45.12 is approximately 57.46.\n"
     ]
    }
   ],
   "source": [
    "call=get_tool_decision(\"What is sum of 12.34 and 45.12?\")\n",
    "tool_to_be_used=TOOLS[call.tool]\n",
    "results=tool_to_be_used(**call.args)\n",
    "results\n",
    "model_response = get_final_answer(\"What is sum of 12.34 and 45.12?\", call_json, results)\n",
    "print(\"model_response: \", model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88b646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
